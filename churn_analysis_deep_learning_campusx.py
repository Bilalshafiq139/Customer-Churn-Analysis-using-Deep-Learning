# -*- coding: utf-8 -*-
"""churn analysis deep learning campusx

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Dg8GUOOF6SeREjJVcwwAB5p32kFGSazV
"""

import pandas as pd

import numpy as np

df = pd.read_csv('/content/Churn_Modelling.csv')

df.head()

df.info()

df.duplicated().sum()

our_customers=df['Exited'].value_counts()
print(f'we have this number of customers with us ', our_customers)

df['Geography'].value_counts()

df.drop(columns=['RowNumber','CustomerId','Surname'],inplace=True)

df.head()

df=pd.get_dummies(df,columns=['Geography','Gender'],drop_first=True)

df.head()

x=df.drop(columns=['Exited'])
y=df['Exited']
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)

x

y

x_train.shape



from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
x_train_scaled=scaler.fit_transform(x_train)
x_test_scaled=scaler.transform(x_test)

x_train_scaled

import tensorflow
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

model=Sequential()
model.add(Dense(3,activation="sigmoid",input_dim=11))
model.add(Dense(1,activation="sigmoid"))

model.summary()

model.compile(loss="binary_crossentropy",optimizer="Adam")

history=model.fit(x_train_scaled,y_train,epochs=100,validation_split=0.2)

model.layers[1].get_weights()

y_log=model.predict(x_test_scaled)

y_pred=np.where(y_log>0.5,1,0)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)

import matplotlib.pyplot as plt

plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])

